# üì∂ Predicci√≥n de Churn ‚Äì Interconnect

La operadora de telecomunicaciones **Interconnect** desea anticipar qu√© clientes cancelar√°n su servicio (churn) para tomar acciones preventivas. Este proyecto implementa un flujo de trabajo completo de Machine Learning para clasificar usuarios seg√∫n probabilidad de abandono.

## üéØ Objetivos

- Unir y depurar los registros de clientes, contratos y servicios (Internet, tel√©fono).  
- Generar nuevas variables que aporten se√±al (p. ej. uso de Internet, l√≠neas m√∫ltiples).  
- Balancear el dataset descompensado (ratio ‚âà 3:1 negativo/positivo).  
- Comparar varios modelos de clasificaci√≥n y seleccionar el √≥ptimo.  
- Optimizar hiperpar√°metros y reducir caracter√≠sticas con RFE.  
- Evaluar el rendimiento final en un conjunto de prueba independiente.

## üîç Flujo de Trabajo

1. **An√°lisis Exploratorio de Datos (EDA)**  
   - Revisi√≥n de medias de duraci√≥n de contrato (activos vs. churn).  
   - Inspecci√≥n de desequilibrio de clases.  
   - Correlaci√≥n entre variables y con la variable objetivo.

2. **Preparaci√≥n de Datos**  
   - **Uni√≥n de tablas:** clientes, contratos, Internet y tel√©fono.  
   - **Eliminaci√≥n de columnas irrelevantes:** IDs, fechas de corte, etc.  
   - **Creaci√≥n de variables:**  
     - `Internet` (s√≠/no), `Phone` (l√≠neas m√∫ltiples / fibra).  
     - Duraci√≥n en d√≠as del contrato.  
     - Etiqueta binaria `Churn`.  
   - **Codificaci√≥n:** One-Hot Encoding de variables categ√≥ricas.  
   - **Escalado:** Min-Max Scaler de todas las variables num√©ricas (rango 0‚Äì1).  
   - **Balanceo:** SMOTE para corregir el desequilibrio de clases.

3. **Divisi√≥n de Conjuntos**  
   - Split en **entrenamiento**, **validaci√≥n** y **prueba**.

4. **Entrenamiento y Ajuste de Modelos**  
   - Modelos probados:  
     - **XGBoost**  
     - **Random Forest**  
   - Hiperpar√°metros optimizados v√≠a b√∫squeda manual (GridSearch exploratorio).  
   - Selecci√≥n de caracter√≠sticas con **Recursive Feature Elimination (RFE)** sobre Random Forest.

5. **Evaluaci√≥n**  
   - M√©trica principal: **AUC-ROC** (objetivo ‚â• 0.88 en validaci√≥n).  
   - M√©tricas secundarias: **Precisi√≥n**, **Recall**, **F1-score**.  
   - Comparaci√≥n frente a baseline (modelo dummy).

## üìä Resultados Principales

- En validaci√≥n se alcanz√≥ **AUC-ROC ‚âà 0.88** con ambos modelos (XGBoost y Random Forest).  
- Tras RFE, Random Forest mantuvo rendimiento similar con menos variables.  
- En conjunto de prueba, el modelo final (Random Forest) obtuvo:  
  - **Exactitud (Accuracy):** 0.77  
  - **Precisi√≥n (Precision):** 0.73  
  - **Recall:** 0.77  
  - **F1-score:** 0.74  
## üèÅ Conclusiones y Recomendaciones

- El modelo **Random Forest** seleccionado cumple con el objetivo de AUC-ROC ‚â• 0.88 y muestra un buen equilibrio entre precisi√≥n y recall.  
- La reducci√≥n de variables mediante RFE no deteriora el rendimiento, facilitando implementaciones m√°s sencillas.  
- El balanceo de clases con SMOTE result√≥ clave para evitar sesgos en la clasificaci√≥n.
- **Despliegue en Producci√≥n:** Integrar el modelo en el sistema de CRM para generar alertas tempranas de churn.  
- **Monitoreo Proactivo de Antig√ºedad**: Implementar alertas autom√°ticas para clientes con `tenure_days` bajos, ya que suelen presentar mayor riesgo de churn.
- **Ofertas Personalizadas en Cargos**: Analizar planes con altos `MonthlyCharges` y dise√±ar promociones para reducir la percepci√≥n de costo.
- **Revisi√≥n de Facturaci√≥n Total**: Detectar clientes con `TotalCharges` muy elevados y ofrecer esquemas de pago fraccionado o descuentos por fidelidad.
- **Engagement de Servicios**: Incentivar el uso de Internet (`InternetService_Yes`) con paquetes de datos adicionales o mejoras de velocidad.
- **Optimizaci√≥n de Planes de L√≠neas M√∫ltiples**: Revisar planes de `MultipleLines_Yes` para asegurar que ofrecen valor agregado y mejorar la retenci√≥n.

## üöÄ C√≥mo Clonar y Preparar el Entorno

```bash
git clone https://github.com/dsc530/tasa_cancelacion.git
